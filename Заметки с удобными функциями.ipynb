{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["o-S4mDekdiQB","Ushxu4LHRggm","VLUE8PBlZgf8"],"authorship_tag":"ABX9TyMecdayKNfLbpi+fFgZHG5Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Пометки для себя, интересные примеры"],"metadata":{"id":"4Mw3e5hiRPSY"}},{"cell_type":"markdown","source":["#1Пример с k-Fold Cross-Validation"],"metadata":{"id":"o-S4mDekdiQB"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import load_iris\n","\n","# Загрузка данных\n","data = load_iris()\n","X = data.data\n","y = data.target\n","\n","# Создание модели\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# k-Fold Cross-Validation\n","scores = cross_val_score(model, X, y, cv=5)\n","\n","# Вывод результатов\n","print(f\"Cross-validation accuracy: {scores.mean():.2f} ± {scores.std():.2f}\")"],"metadata":{"id":"RvtadOMTRRQ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. k-Fold Cross-Validation (k-блочная кросс-валидация)\n","Данные делятся на k равных частей (фолдов).\n","\n","Модель обучается на k-1 фолдах и тестируется на оставшемся фолде.\n","\n","Процесс повторяется k раз, и каждый раз выбирается новый фолд для тестирования.\n","\n","Результаты усредняются, чтобы получить общую оценку модели."],"metadata":{"id":"3-U1OyeZdv3-"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","scores = cross_val_score(model, X, y, cv=5)  # 5-Fold Cross-Validation\n","print(f\"Cross-validation accuracy: {scores.mean():.2f} ± {scores.std():.2f}\")"],"metadata":{"id":"hyL_VTMpR598"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Leave-One-Out Cross-Validation (LOOCV, кросс-валидация с исключением одного)\n","Это частный случай k-Fold, где k равно количеству наблюдений в данных.\n","\n","Модель обучается на всех данных, кроме одного наблюдения, которое используется для тестирования.\n","\n","Процесс повторяется для каждого наблюдения.\n","\n","Этот метод очень точный, но требует больших вычислительных ресурсов."],"metadata":{"id":"DdH8TXXgdtN4"}},{"cell_type":"code","source":["from sklearn.model_selection import LeaveOneOut\n","\n","loo = LeaveOneOut()\n","scores = cross_val_score(model, X, y, cv=loo)\n","print(f\"LOOCV accuracy: {scores.mean():.2f} ± {scores.std():.2f}\")"],"metadata":{"id":"Z29-DI9DR8Or"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Stratified k-Fold Cross-Validation (стратифицированная кросс-валидация)\n","Этот метод используется для задач классификации, чтобы обеспечить, что каждый фолд содержит примерно одинаковое распределение классов, как и в исходных данных.\n","\n","Это помогает избежать ситуаций, когда в фолде не хватает примеров одного из классов"],"metadata":{"id":"45B9Cd5wdqoC"}},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold\n","\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","scores = cross_val_score(model, X, y, cv=skf)\n","print(f\"Stratified Cross-validation accuracy: {scores.mean():.2f} ± {scores.std():.2f}\")"],"metadata":{"id":"jRy55ugFR-Z6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Time Series Cross-Validation (кросс-валидация для временных рядов)\n","Используется для задач, где данные имеют временную зависимость.\n","\n","Данные делятся так, чтобы модель обучалась на прошлых данных и тестировалась на будущих."],"metadata":{"id":"xt-nNLHOdmUB"}},{"cell_type":"code","source":["from sklearn.model_selection import TimeSeriesSplit\n","\n","tscv = TimeSeriesSplit(n_splits=5)\n","scores = cross_val_score(model, X, y, cv=tscv)\n","print(f\"Time Series Cross-validation accuracy: {scores.mean():.2f} ± {scores.std():.2f}\")"],"metadata":{"id":"ahJ4x-xcSAWx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#2 Если модель показывает высокий скор на обучающих данных, но низкий на тестовых, это сигнал о переобучении.\n","Чтобы исправить это:\n","Упростите модель.\n","Используйте регуляризацию.(В логистической регрессии используйте параметр C (чем меньше C, тем сильнее регуляризация).\n","В случайном лесе используйте параметр max_depth для ограничения глубины деревьев.)\n","Увеличьте объем данных.\n","Уменьшите количество признаков.\n","Используйте кросс-валидацию.например, KFold\n","Применяйте ансамблевые методы.\n","в нейронках -использ. Dropout — метод, который случайным образом отключает часть нейронов во время обучения,"],"metadata":{"id":"Ushxu4LHRggm"}},{"cell_type":"markdown","source":["1. Упростить модель\n","Используйте более простую модель, которая не будет слишком сильно подстраиваться под обучающие данные.\n","\n","Например:\n","\n","Замените сложную модель (например, случайный лес или градиентный бустинг) на более простую (например, логистическую регрессию или k-ближайших соседей).\n","\n","Уменьшите количество деревьев в случайном лесе или глубину деревьев."],"metadata":{"id":"IayERAnmeT45"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n","model.fit(X_train, y_train)"],"metadata":{"id":"Nbv3A9ctRpXC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","2. Регуляризация\n","Регуляризация добавляет штраф за сложность модели, чтобы она не переобучалась.\n","\n","Например:\n","\n","В логистической регрессии используйте параметр C (чем меньше C, тем сильнее регуляризация).\n","\n","В случайном лесе используйте параметр max_depth для ограничения глубины деревьев."],"metadata":{"id":"pyyRiiNfeQB6"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","model = LogisticRegression(C=0.1, max_iter=1000)\n","model.fit(X_train, y_train)"],"metadata":{"id":"bAuldecrRrfQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Использовать Dropout (для нейронных сетей)\n","В нейронных сетях можно использовать Dropout — метод, который случайным образом отключает часть нейронов во время обучения, чтобы предотвратить переобучение."],"metadata":{"id":"OiJQBGk5eJxe"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    Dropout(0.5),\n","    Dense(1, activation='sigmoid')\n","])\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"],"metadata":{"id":"iedqmquYRwdV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Уменьшить количество признаков\n","Если в данных слишком много признаков, модель может переобучиться. Удалите избыточные или нерелевантные признаки.\n","\n","Используйте методы отбора признаков, такие как:\n","\n","Корреляционный анализ.\n","\n","Методы отбора признаков (например, SelectKBest)."],"metadata":{"id":"LEoZq2did7wF"}},{"cell_type":"code","source":["from sklearn.feature_selection import SelectKBest, f_classif\n","\n","selector = SelectKBest(f_classif, k=10)  # Выбираем 10 лучших признаков\n","X_train_selected = selector.fit_transform(X_train, y_train)\n","X_test_selected = selector.transform(X_test)"],"metadata":{"id":"dsOObpgeR1b0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. Использовать ансамблевые методы\n","Ансамблевые методы, такие как стекинг (stacking) или бэггинг (bagging), могут помочь уменьшить переобучение.\n","\n","Например, используйте BaggingClassifier с простой моделью."],"metadata":{"id":"w3_I7O1Id43B"}},{"cell_type":"code","source":["from sklearn.ensemble import BaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","model = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)"],"metadata":{"id":"FppzXSVZR3aT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["немного про корреляционную матрицу сюда закину"],"metadata":{"id":"FftXDp2XZQ1_"}},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Пример данных\n","data = pd.DataFrame({\n","    'feature1': [1, 2, 3, 4, 5],\n","    'feature2': [2, 3, 4, 5, 6],\n","    'feature3': [10, 20, 30, 40, 50],\n","    'target': [0, 1, 0, 1, 0]\n","})\n","\n","# Вычисление корреляции\n","correlation_matrix = data.corr()\n","\n","# Визуализация корреляционной матрицы\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n","plt.show()\n","\n","# Отбор признаков с высокой корреляцией с целевой переменной\n","target_correlation = correlation_matrix['target'].abs()\n","selected_features = target_correlation[target_correlation > 0.5].index.tolist()\n","print(\"Выбранные признаки:\", selected_features)"],"metadata":{"id":"FTY4UOrYZVGv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3 Методы отбора признаков (SelectKBest)\n","SelectKBest — это метод, который выбирает фиксированное количество (k) наиболее важных признаков на основе статистических тестов.\n","\n","Как это работает:\n","Выбирается статистический тест для оценки важности признаков (например, ANOVA F-тест для задач классификации или корреляция для задач регрессии).\n","\n","Признаки ранжируются по важности.\n","\n"," 1. Выбираются k наиболее важных признаков."],"metadata":{"id":"VLUE8PBlZgf8"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.feature_selection import SelectKBest, f_classif\n","\n","# Загрузка данных\n","data = load_iris()\n","X = data.data\n","y = data.target\n","\n","# Выбор 2 наиболее важных признаков\n","selector = SelectKBest(score_func=f_classif, k=2)\n","X_new = selector.fit_transform(X, y)\n","\n","# Вывод выбранных признаков\n","print(\"Выбранные признаки:\", selector.get_support(indices=True))\n","print(\"Новые данные:\", X_new)"],"metadata":{"id":"B2EAhqcPZg7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Другие методы отбора признаков\n","3.1. RFE (Recursive Feature Elimination, рекурсивное исключение признаков)\n","Метод, который рекурсивно удаляет наименее важные признаки на основе весов модели (например, коэффициентов линейной регрессии или важности признаков в случайном лесе).\n","\n","Постепенно уменьшает количество признаков, пока не останется нужное количество."],"metadata":{"id":"hw-CLLOeZsoK"}},{"cell_type":"code","source":["from sklearn.feature_selection import RFE\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Создание модели\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# RFE с выбором 2 признаков\n","rfe = RFE(model, n_features_to_select=2)\n","X_new = rfe.fit_transform(X, y)\n","\n","# Вывод выбранных признаков\n","print(\"Выбранные признаки:\", rfe.support_)\n","print(\"Ранги признаков:\", rfe.ranking_)"],"metadata":{"id":"f4hRx1bhZtb9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. SelectFromModel\n","Метод, который использует обученную модель для выбора признаков.\n","\n","Признаки выбираются на основе важности, которую модель присваивает каждому признаку (например, важность признаков в случайном лесе или коэффициенты в линейной регрессии).\n"],"metadata":{"id":"YUfPun8ZZ0MN"}},{"cell_type":"code","source":["from sklearn.feature_selection import SelectFromModel\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Создание модели\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Обучение модели\n","model.fit(X, y)\n","\n","# Выбор признаков на основе важности\n","selector = SelectFromModel(model, threshold=\"median\", prefit=True)\n","X_new = selector.transform(X)\n","\n","# Вывод выбранных признаков\n","print(\"Выбранные признаки:\", selector.get_support())\n","print(\"Новые данные:\", X_new)"],"metadata":{"id":"mw51jV2hZyT7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. L1-регуляризация (Lasso)\n","Метод, который использует L1-регуляризацию для выбора признаков.\n","\n","L1-регуляризация добавляет штраф за небольшие коэффициенты, что приводит к тому, что многие коэффициенты становятся равными нулю, и таким образом выбираются только важные признаки."],"metadata":{"id":"Z-mMYD84aZWk"}},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","\n","# Создание модели с L1-регуляризацией\n","model = Lasso(alpha=0.01)\n","\n","# Обучение модели\n","model.fit(X, y)\n","\n","# Вывод коэффициентов\n","print(\"Коэффициенты:\", model.coef_)\n","print(\"Выбранные признаки:\", model.coef_ != 0)"],"metadata":{"id":"FzNs8AVAaZ9Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Для перобработки данных, тип: Объект"],"metadata":{"id":"OLlmllXIfF4K"}},{"cell_type":"code","source":["unprocessed_cat_features = cat_features_data.select_dtypes(include=[object]).columns.to_list()"],"metadata":{"id":"WP0nUj1jfFpP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Понравилась тепловая карта"],"metadata":{"id":"epdyXW4XhIFV"}},{"cell_type":"code","source":["plt.figure(figsize=(12, 8))\n","sns.heatmap(data.corr(numeric_only=True), annot=True, cmap='viridis');"],"metadata":{"id":"SVoqAiDIfMed"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Этот фрагмент кода объединяет DataFrame data.iloc[:len(train)] и Series y в один DataFrame, добавляя столбец y к DataFrame data."],"metadata":{"id":"eWlQTDd7jaH2"}},{"cell_type":"code","source":["data_and_target = pd.concat([data.iloc[:len(train)], y], axis=1) #Gold Feature\n","data_and_target"],"metadata":{"id":"eVoJZI_sjanF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Проанализируйте, какие столбцы являются существенными и влияют на предсказание, а какие нет. Удалите ненужные столбцы по вашему мнению."],"metadata":{"id":"Lnh_EgEC9eKM"}},{"cell_type":"code","source":["data = pd.concat([numeric_data, categorial_data], axis=1)\n","data.drop(columns=['name', 'numDeadRelations', 'popularity'], inplace = True)\n","data"],"metadata":{"id":"xoX3pKbK9gwY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Эта строка кода выполняет следующие действия:\n","\n","Выбирает столбец 'isAlive' из DataFrame data_and_target.\n","\n","Считает количество уникальных значений в этом столбце."],"metadata":{"id":"4uDulAIoq57d"}},{"cell_type":"code","source":["data_and_target['isAlive'].value_counts()"],"metadata":{"id":"NBfKLXi_nmhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_and_target[data_and_target['isPopular'] == 1]['isAlive'].value_counts()"],"metadata":{"id":"T9W8m1BrnnuQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Фильтрует строки в DataFrame data_and_target, где значение столбца 'isPopular' равно 0.\n","\n","Выбирает столбец 'isAlive' для отфильтрованных строк.\n","\n","Считает количество уникальных значений в столбце 'isAlive' для этих строк."],"metadata":{"id":"GDERwQ7hrBao"}},{"cell_type":"code","source":["data_and_target[data_and_target['isPopular'] == 0]['isAlive'].value_counts()"],"metadata":{"id":"Qrt93bK4nueP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Создайте переменные X, которая будет хранить только значения признаков, и y, которая будет хранить только значения целевой переменной."],"metadata":{"id":"ejJii3oZp7mv"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(data)\n","\n","# y уже создан выше\n","scaled_train = scaled_data[:len(train)]\n","scaled_test = scaled_data[len(train):]"],"metadata":{"id":"QV6KK4ksp4-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Проверка статистической значимости категориальных столбцов\n","from scipy.stats import chi2_contingency\n","\n","# Фильтрация категориальных столбцов\n","categorical_columns = data.select_dtypes(include='object').columns\n","\n","# Хранение результатов хи-квадрат теста\n","chi2_results = {}\n","\n","for col in categorical_columns:\n","    # Создание таблицы сопряженности\n","    contingency_table = pd.crosstab(data[col], data['isAlive'])\n","\n","    # Применение хи-квадрат теста\n","    chi2, p, dof, expected = chi2_contingency(contingency_table)\n","\n","    # Сохранение p-значения в словарь\n","    chi2_results[col] = p\n","\n","# Вывод результатов\n","for col, p_value in chi2_results.items():\n","    print(f\"Колонка: {col}, p-значение: {p_value}\")\n","\n","    if p_value < 0.05:\n","        print(f\"Признак '{col}' статистически значим (p < 0.05)\")\n","    else:\n","        print(f\"Признак '{col}' не является статистически значимым (p >= 0.05)\")"],"metadata":{"id":"g4qY_F3L2Qk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Создаем пустой список для хранения результатов\n","correlation_results = []\n","\n","# Целевая переменная\n","target = 'isAlive'\n","\n","# Проходим по всем числовым колонкам, кроме целевой переменной\n","for column in numeric_columns:\n","    if column != target:\n","        # Вычисляем коэффициент корреляции и p-значение\n","        corr, p_value = pearsonr(data_encoded[column], data_encoded[target])\n","        correlation_results.append([column, corr, p_value])\n","\n","# Преобразуем результаты в DataFrame\n","correlation_df = pd.DataFrame(correlation_results, columns=['Feature', 'Correlation', 'P-value'])\n","\n","# Анализ статистической значимости\n","correlation_df['Significant'] = correlation_df['P-value'].apply(lambda x: 'Yes' if x < 0.05 else 'No')\n","\n","# Выводим таблицу с анализом\n","print(correlation_df)"],"metadata":{"id":"NYC7e_6A2xBn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Для отрисовки Лосса"],"metadata":{"id":"y5XtmBIQGN2G"}},{"cell_type":"code","source":["plot_roc_curve(y_train, grid_cat.predict_proba(X_train)[:, 1],\n","               y_valid, grid_cat.predict_proba(X_valid)[:, 1],\n","               model='CatBoostClassifier with grid_search')"],"metadata":{"id":"3Y5HrP0CGQjw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Отрисовка пайплайна"],"metadata":{"id":"eF0-bKIDGT_t"}},{"cell_type":"code","source":["pipe = Pipeline(\n","    steps=[\n","        ('preproc', col_transformer),\n","        ('model', LogisticRegression(C=best_C, solver=best_solver))\n","    ])\n","\n","pipe.fit(train[X], train[y])"],"metadata":{"id":"H4PVaFNCGV4p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Оптимальные параметры"],"metadata":{"id":"kCLhLN_OG7oL"}},{"cell_type":"code","source":["regularization = clf.cv_results_['param_model__C'].data\n","solvers = clf.cv_results_['param_model__solver'].data\n","auc_score = clf.cv_results_['mean_test_score']"],"metadata":{"id":"jfuEN1DBG5ou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pairplot для числовых признаков и целевой переменной\n","sns.pairplot(train_data[num_cols + [target_col]], hue=target_col)\n","plt.show()"],"metadata":{"id":"nXzbaTfLG6AO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Оптимизация гиперпараметров\n","best_score = 0\n","best_params = {}\n","\n","learning_rates = [0.01, 0.05, 0.1, 0.2]\n","iterations = [100, 200, 500]\n","\n","for lr in learning_rates:\n","    for it in iterations:\n","        model = CatBoostClassifier(iterations=it, learning_rate=lr, cat_features=cat_cols, silent=True)\n","        model.fit(X_train, y_train)\n","\n","        y_pred_valid = model.predict_proba(X_valid)[:, 1]\n","        roc_auc = roc_auc_score(y_valid, y_pred_valid)\n","\n","        print(f\"ROC-AUC с learning_rate={lr} и iterations={it}: {roc_auc:.4f}\")\n","\n","        if roc_auc > best_score:\n","            best_score = roc_auc\n","            best_params = {'learning_rate': lr, 'iterations': it}\n","\n","print(f\"Лучший ROC-AUC: {best_score:.4f} с параметрами: {best_params}\")"],"metadata":{"id":"3rq3w2zrK9Ca"},"execution_count":null,"outputs":[]}]}